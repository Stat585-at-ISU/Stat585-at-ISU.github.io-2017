---
title: "Ethics of Reproducible Research"
author: "Kiegan Rice"
topic: "07"
layout: post
root: ../../../
---


## Question 6: Why didn't the peer review system identify the problems?  
I  think the peer review system failed to identify the problems with this paper before it was published because the main problems in this paper were the data collection and data management. Peer reviewers are generally focused on the write-up of the study and how clearly the results are presented, as well as questioning the set-up of the study and thus what conclusions can actually be drawn given the results. From my understanding, it is not common for peer reviewers to receive the data along with the paper, and thus the peer review process does not include verifying the data itself and making sure that the same numerical/graphical results can be reached. However, even if that is the case in some fields, this particular paper still would have slipped through the cracks because the issue was with the data itself. 

Given the data from that study, the analysis may have been conducted correctly and done well and completely, and peer reviewers could have reached the same conclusions as the paper. However, if the issue is with the data being falsified, there is no way to catch that unless there are either red flags in the results or you contact the sources of the data to verify that the data was collected correctly (here, that would have to be 'uSamp', the survey company, rather than the author, LaCour). However, as far as 'red flags' in the results, it appears to me that there were some - extremely high response rates, very significant results - that should have been more carefully looked at by both the co-author and the peer reviewers, if they were at all familiar with studies of a similar nature. 

This case appears to be an example of 'trusting the data' too much. We live in such a data-inundated world that I think it would be easy for academics in this day and age to 'trust the data' and see what we can learn from it, rather than 'testing the data' to find out if it's even real first.
