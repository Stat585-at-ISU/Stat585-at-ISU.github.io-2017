---
title: "Reproducability In Programming"
author: "Vinny Paris"
topic: "08"
layout: post
root: ../../../
---


"When we publish articles containing 􏰂gures which were generated by computer􏰍 we also publish the complete software environment which generates the 􏰂figures"
That is overall message of the first paper. It was interesting though listening to their "scandals" and how it sounds like modern programming and saving would make all the problems just dissappear (save early, save often).

Sounds like the first major step is that the researcher needs to *want* to make repoducable research. A disinterested researcher most likely won't implement anything. As such, we need to win the war on the hearts and the minds of the authors to get them to understand why reproducability is important. Next major thing is to use the internet to keep up communications between peolpe and allow for easy sharing. Trying to build on free-ware (like R) is a definite advantage since it allows everyone to access it without worrrying about costs on their part. Also use, quantatitive programming enviorment when possible (I find this a strange remark since I don't know what else you would use? Army of interns to work with matrix calculations?). Finally statisticians are at a unique point in the scientific process to make it reporducable and we should use this power for good. That is roughly the ideas from the first paper.


In the second the author's make it sound like there is a crisis happening in scientific computations. They seem to push heavily that the code needs to be presented at the hip witht the major conclusions and that if possible one should be able to work through it as they read the paper. Since programming as gotten to be so large and ambitious we really can't afford to let people try to build it blind unless it is a *very* small program. It's just easier to give them the code. Cross-platform QPE's have also became more well known and accessible which helps. 

"....if everyone in a research team knows that everything they do is going to someday be published for reproducibility, they will behave differently and will do better work." I really like the bluntness of this argument. They also really helped push with their wavelit the idea that certain things can be held in different files and that they should ultimately be built together but that they don't need to be created and stored as one large file. This allows for quick access to the different files for specific details (like Broilerplates, Datasets or installation stuff). I will say the authors arguments against that reproducability will lead to the degradation of intellectual capital to be weak. It seems like a stronger argument could be built if they also included that later down the road if you bring someone onto the team or even if you need to look backwards reporducability would be extremely desirable (i.e. it's will help the researcher if it's repoducable in the long run over time. Same idea as literate programming). And the authors in that argument appear to be playing a definitions game about what intellectual capital *is* and ignoring the issues raised. 
