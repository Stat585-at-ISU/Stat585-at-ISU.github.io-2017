---
title: "Prioritizing Reproducability to Promote Reliability"
author: "Jo Papio "
topic: "08"
layout: post
root: ../../../
---

## Discuss the commonalities and changes in the themes and solutions.  

Broadly speaking, the authors in both articles wish to call attention to what is arguably an ancient phenomenon, one which the scientific method, even in its infancy, sought to overcome: primarily, *the scope and scale of our collective ignorance and our penchant to underestimate it*, but also, and not unrelated, *the issue of human hubris* and *our tendency to overlook or even fail to recognize our own mistakes*. Science and empirical endeavors strive to recognize these problems so that we can then, to the extent possible, isolate them, thus attempting minimize their effect on discovery. However, the authors of both articles point to the reemergence of these problems as scientific computation becomes more complex and also more readily available; much like in the early days of empirical effort, human propensity to hubris, underestimation of our ignorance, and tendency to overlook or fail to recognize our errors, once again threaten to plague forward progress. 

Even when what they call "scientific computing" was arguably in its infancy because computing power was still relatively limited compared to what it is today, Donoho in particular (in addition to the man he references, Claerbout) was already calling attention to the problems outlined above, which, in the ensuing decades, have only gotten worse.

I do not believe the authors are being even remotely hyperbolic when they claim that this issue is indeed a crisis: it threatens to derail scientific progress, causing empirically minded folks to expend countless hours and immeasurable effort essentially making the same mistakes that others have already made, or to toil on problems based on faulty assumptions and less than rigorous evidence. By calling attention to the lack of *reproducibility* currently present within scientific computing, they are also calling attention to the decay of a central pillar of the scientific method: *reliability*.

We could all benefit from Dono's example to "not trust himself to do good work unless his results were subject to open criticism by others". It points to the most obvious direction in the effort of a solution to this crisis. While not a guarantee to prevent errors, it can be helpful in detecting them: those of us to engage in the practice of empirical endeavors should make a habit and practice of documenting what we are doing, or at least, what we think we are doing, so that others can retrace our footsteps, seeing if the descriptions of our actions indeed match what we have done. 

One of the crucial assumptions that developed as the scientific method matured prior to the computing age was that practitioners assumed they could not trust themselves, and thus needed to make their assumptions and practices broadly available so as to be made transparent and thus questionable and subject to critique. While this assumption still stands broadly, it is unfortunately absent in the less mature practice of scientific computing. We are currently in the growing pains of making that assumption more standard, but should we succeed, the effort will certainly be worth it.
