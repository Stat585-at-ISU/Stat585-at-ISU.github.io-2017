---
title: "Reproducibility in the large-scale computation world"
author: "Kiegan Rice "
topic: "08"
layout: post
root: ../../../
---


## Discuss the commonalities and changes in the themes and solutions.  

Although these two papers are focused on the same computational software, `WaveLab`, the differences between the tone and focus of the two articles shows how much computational science has changed in the last few decades. The first paper, "WaveLab and Reproducible Research", focuses on communication between collaboraters (and mentions the grad student to professor communciation gap) and issues where various parameters were used for the same model and it was hard to tell which parameters produced which output, images, etc. for papers. Documentation was not ideal for keeping track of all the various sets of parameters that were used and what the corresponding results were. The second paper, "15 Years of Reproducible Research in Computational Harmonic Analysis", focuses much more on large-scale computation, which is expected since computing has gotten more and more powerful as time has gone on. When you can run a fine grid of values for a whole set of different parameters, you are keeping track of WAY more output and everything is just on a larger scale. It also focuses on how with 'computational simulations', we can't even really be sure whether the results we are getting are accurate or worth anything - it is difficult to ensure accuracy within the field of computational simulation. The fact that we are now in a 'large-scale' computational world brings a whole host of new problems - are we even sure if the function was used correctly? Was the correct range of parameters used? The main difference in the themes of these two papers had to do with just that - the changes in computing power. The differences in solutions were because of that change as well. The first paper mostly mentioned the ability to keep track of what each function is doing and make sure that code is easily searchable when something needs to be checked. Help files for each function are an important part of any computational software. The second paper continued this theme, but also talked about making sure that any paper explaining how the software is used has the code underlying and makes that code fully available to article readers (or those searching through the documentation). Things like `knitr` in RMarkdown make this much easier, and as I was reading that article I kept thinking about how much easier it makes reproducibility for statisticians and data scientists. Every single function call and line of code is underlying in the file that creates the paper, so you can easily check things or change and update things. I think the main thing I got out of these papers were just that as computation gets larger and more powerful, we have to make everything even more transparent and available for readers. It is the responsible things to do when we are using powerful computational tools that may or may not be used correctly all the time by users and researchers.

